{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qnJ1qJKfOvTs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qnJ1qJKfOvTs",
        "outputId": "43c79474-a98e-4570-8f68-389a7d05806b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sympy==1.12\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.12/dist-packages (from sympy==1.12) (1.3.0)\n",
            "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.9.0+cu126 requires sympy>=1.13.3, but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.12\n"
          ]
        }
      ],
      "source": [
        "!pip install sympy==1.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fmCucnszfgEc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmCucnszfgEc",
        "outputId": "ae7a4353-62e5-4f29-a995-3b75b421a2d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa84aaa",
      "metadata": {
        "id": "1fa84aaa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a96b806c",
      "metadata": {
        "id": "a96b806c"
      },
      "outputs": [],
      "source": [
        "#configuration for GPT model having 124 million parameters\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256, #1024\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae719821",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ae719821",
        "outputId": "1f9471bc-31b1-48c0-c228-87ee5f641445"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntext\\ntoken id\\ntoken embedding\\nposition embedding\\ninput embedding\\ndropout\\nlayer normalization\\nself-attention\\ndropout\\nresidual connection\\nlayer normalization\\nfeed forward neural network\\ndropout\\nresidual connection\\nlayer normalization\\noutput logits\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "text\n",
        "token id\n",
        "token embedding\n",
        "position embedding\n",
        "input embedding\n",
        "dropout\n",
        "layer normalization\n",
        "self-attention\n",
        "dropout\n",
        "residual connection\n",
        "layer normalization\n",
        "feed forward neural network\n",
        "dropout\n",
        "residual connection\n",
        "layer normalization\n",
        "output logits\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d66e22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16d66e22",
        "outputId": "cfdfdcc6-21e5-4325-9797-1230c20db407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d46531",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00d46531",
        "outputId": "5d377304-7a3e-4a5b-a739-43149006dc77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'vocab_size': 50257,\n",
              " 'context_length': 256,\n",
              " 'emb_dim': 768,\n",
              " 'n_heads': 12,\n",
              " 'n_layers': 12,\n",
              " 'drop_rate': 0.1,\n",
              " 'qkv_bias': False}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#class for multi head attention_tags\n",
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_head\"\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_q = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_k = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_v = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = torch.nn.Linear(d_out, d_out)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        key = self.W_k(x)\n",
        "        query = self.W_q(x)\n",
        "        value = self.W_v(x)\n",
        "\n",
        "        #reshaping key, query, value as each token with 12 heads and each head with 64 dimensions\n",
        "        key = key.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        query = query.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        value = value.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        #transposing to get dimensions as batch size, each head with num_tokens and each token with head_dim (b, num_heads, num_tokens, head_dim)\n",
        "        key = key.transpose(1,2)\n",
        "        query = query.transpose(1,2)\n",
        "        value = value.transpose(1,2)\n",
        "\n",
        "        #calculating attention score by multiplication of query and key transpose (num_tokens, head_dim) @ (head_dim, num_tokens) = (num_tokens, num_tokens)\n",
        "        attn_scores = query @ key.transpose(2,3)\n",
        "\n",
        "        #creating mask to make the future tokens to have -inf attention score and after softmax will become zero as probability\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores = attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        #attention score is divided by sqrt of key dimension to avoid large values and then softmax is applied to get normalize weights\n",
        "        attn_weights = torch.softmax(attn_scores / key.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        #multiplying attention weights with value to get context vector (b, num_heads, num_tokens, num_tokens) * (b, num_heads, num_tokens, head_dim) = (b, num_heads, num_tokens, head_dim)\n",
        "        context_vector = (attn_weights @ value).transpose(1,2)\n",
        "        context_vector = context_vector.contiguous().view(b, num_tokens, d_in)\n",
        "        context_vector = self.out_proj(context_vector)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "#class for transformer block\n",
        "class  TransformerBlock(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(d_in=cfg['emb_dim'], d_out=cfg['emb_dim'], context_length=cfg['context_length'],\n",
        "                                    num_heads=cfg['n_heads'], dropout=cfg['drop_rate'], qkv_bias=cfg['qkv_bias'])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 =  LayerNorm(cfg['emb_dim'])\n",
        "        self.norm2 =  LayerNorm(cfg['emb_dim'])\n",
        "        self.drop_shortcut = torch.nn.Dropout(cfg['drop_rate'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.attn(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "        return x\n",
        "\n",
        "#class for layer normalization\n",
        "class  LayerNorm(torch.nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = torch.nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = torch.nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * x_norm + self.shift\n",
        "\n",
        "#class for GELU activaton function\n",
        "class GELU(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) *(x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "#class for feed forward neural network\n",
        "class FeedForward(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(cfg['emb_dim'], 4*cfg['emb_dim']),\n",
        "            GELU(),\n",
        "            torch.nn.Linear(4*cfg['emb_dim'], cfg['emb_dim'])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class GPTmodel(torch.nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.token_emb = torch.nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
        "        self.pos_emb = torch.nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
        "        self.drop_emb = torch.nn.Dropout(cfg['drop_rate'])\n",
        "\n",
        "        self.trf_blocks = torch.nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg['n_layers'])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
        "        self.out_head = torch.nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_length = in_idx.shape\n",
        "        token_embeds = self.token_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_length, device=in_idx.device))\n",
        "        x = token_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits #shape: (batch_size, seq_length, vocab_size)\n",
        "GPT_CONFIG_124M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99a75443",
      "metadata": {
        "id": "99a75443"
      },
      "outputs": [],
      "source": [
        "# function to convert text to token ids and vice versa\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff46831",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ff46831",
        "outputId": "089ce12e-a926-445f-ad1f-ac735939d220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[15496,     0,   314,   716]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 4])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text1 = 'Hello! I am'\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "input_ids=text_to_token_ids(text1, tokenizer)\n",
        "print(input_ids)\n",
        "input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a13cd6",
      "metadata": {
        "id": "08a13cd6"
      },
      "outputs": [],
      "source": [
        "#generating text from the model\n",
        "def generate_text(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None: #taking top k logits and setting rest to -inf\n",
        "            top_logits, _ = torch.topk(logits, top_k, dim=-1)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        if temperature>0.0: #applying temperature scaling and sampling from the distribution\n",
        "            logits = logits/temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1) #(batch_size, 1)\n",
        "        else:\n",
        "            next_token = torch.argmax(logits, dim=-1, keepdim=True) #(batch, 1)\n",
        "\n",
        "        if next_token == eos_id: #stop generation if end of sequence token is generated\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, next_token), dim=1) #(batch,n_tokens+1) concatenating the new token to the existing sequence\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "621cec8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621cec8b",
        "outputId": "60bda97e-37e2-4a60-87d1-2318d9b9ed89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[15496,     0,   314,   716, 13240, 11381,  4307,  7640, 33491, 12254,\n",
            "         26050,  8942, 44168, 35735]])\n",
            "Hello! I am Laur inhab Distrinereplacefly279 Burn issuerurnal\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "model.eval() # set the model to evaluation mode , stops acting like training, dropout works as identity\n",
        "result_tokens = generate_text(model=model, idx=input_ids, max_new_tokens=10, context_size=GPT_CONFIG_124M['context_length'])\n",
        "print(result_tokens)\n",
        "decoded_output = tokenizer.decode(result_tokens[0].tolist())\n",
        "print(decoded_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9566a479",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9566a479",
        "outputId": "983128f8-2e7e-4396-e53b-2b26d633bedc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.eot_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d05d60",
      "metadata": {
        "id": "15d05d60"
      },
      "outputs": [],
      "source": [
        "#function to generate and print text from the model\n",
        "def generate_and_print(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_tokens = generate_text(model, encoded, max_new_tokens=50, context_size=context_size, temperature=0.8, top_k=50, eos_id=tokenizer.eot_token)\n",
        "    decoded_text = token_ids_to_text(generated_tokens, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\",\" \"))\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2d0f5b",
      "metadata": {
        "id": "ca2d0f5b"
      },
      "outputs": [],
      "source": [
        "#will create now dataset and dataloader using bpe_tokenizer and the verdict text file\n",
        "#we will use this class in dataloader to create batches of data\n",
        "class GPTDatasetv1:\n",
        "    def __init__(self, text, tokenizer, max_len, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "        token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0, len(token_ids)-max_len, stride):\n",
        "            input_id = token_ids[i:i+max_len]\n",
        "            target_id = token_ids[i+1:i+max_len+1]\n",
        "            self.input_ids.append(torch.tensor(input_id))\n",
        "            self.target_ids.append(torch.tensor(target_id))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "#dataloader function to create batches of data\n",
        "def create_dataloaderv1(text, batch_size=4, max_len=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset1 = GPTDatasetv1(text, tokenizer, max_len, stride)\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d350cdcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d350cdcc",
        "outputId": "92febb67-7df5-4162-9f40-4d2cd972d966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total tokens: 5145, total characters: 20479\n"
          ]
        }
      ],
      "source": [
        "#Dataset is now stored in variable content\n",
        "# with open(\"/content/drive/MyDrive/Dataset/the-verdict.txt\") as file:\n",
        "with open(\"/content/drive/MyDrive/Khanakh/Dataset/the-verdict.txt\") as file:\n",
        "    content = file.read()\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "total_tokens = len(tokenizer.encode(content))\n",
        "total_characters = len(content)\n",
        "print(f\"total tokens: {total_tokens}, total characters: {total_characters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ecd329",
      "metadata": {
        "id": "b7ecd329"
      },
      "outputs": [],
      "source": [
        "#training and validation dataloaders\n",
        "train_ratio = 0.9\n",
        "tokens = tokenizer.encode(content)\n",
        "split = int(train_ratio * len(tokens))\n",
        "\n",
        "train_tokens = tokens[:split]\n",
        "val_tokens = tokens[split:]\n",
        "\n",
        "train_data = tokenizer.decode(train_tokens)\n",
        "val_data = tokenizer.decode(val_tokens)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataloader = create_dataloaderv1(text=train_data, batch_size=2, max_len=GPT_CONFIG_124M['context_length'],\n",
        "                                    stride=GPT_CONFIG_124M['context_length'], shuffle=True, drop_last=True, num_workers=0)\n",
        "\n",
        "val_dataloader = create_dataloaderv1(text=val_data, batch_size=2, max_len=GPT_CONFIG_124M['context_length'],\n",
        "                                    stride=GPT_CONFIG_124M['context_length'], shuffle=False, drop_last=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204e78f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "204e78f3",
        "outputId": "00beccb8-a485-4ac0-8392-8699f96479b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "for x,y in train_dataloader:\n",
        "    print(x.shape, y.shape)\n",
        "#this shows us total lines as total number of batches with each batch having 2 samples (input and target) of (2, 1024) shape which means batch size (sequences) is 2 and each sample has 1024 tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1de9fb8",
      "metadata": {
        "id": "c1de9fb8"
      },
      "outputs": [],
      "source": [
        "#function to calculate loss using cross entropy loss per batch\n",
        "def compute_loss(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "#calculate average loss for specified number of batches from dataloader\n",
        "def calc_loss_loader(dataloader, model, device, num_batches=None):\n",
        "    total_loss = 0\n",
        "    if len(dataloader) == 0:\n",
        "        return float('nan')\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(dataloader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(dataloader))\n",
        "        for i, (input_batch, target_batch) in enumerate(dataloader):\n",
        "            if i < num_batches:\n",
        "                loss = compute_loss(input_batch, target_batch, model, device)\n",
        "                total_loss += loss.item()\n",
        "            else:\n",
        "                break\n",
        "        avg_loss = total_loss / num_batches\n",
        "    return avg_loss\n",
        "\n",
        "#function to calculate training and validation loss at regular intervals(batches/eval_iter)\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68fdd1c9",
      "metadata": {
        "id": "68fdd1c9"
      },
      "outputs": [],
      "source": [
        "#training loop for llm model\n",
        "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
        "    #initialize list to track training and validation loss and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [],[],[]\n",
        "    tokens_seen, global_step = 0, 0\n",
        "\n",
        "    #training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train() #set the model to training mode\n",
        "        for (input_batch, target_batch) in train_loader:\n",
        "            optimizer.zero_grad() #clear previous gradients\n",
        "            loss = compute_loss(input_batch, target_batch, model, device)\n",
        "            loss.backward() #backpropagation (calculate loss backwards)\n",
        "            optimizer.step() #update model parameters\n",
        "            tokens_seen += input_batch.numel() #number of tokens seen so far\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Epoch {epoch+1}, step {global_step}: train_loss = {train_loss:.3f}, val_loss = {val_loss:.3f}, tokens_seen = {tokens_seen}\")\n",
        "\n",
        "        generate_and_print(model, tokenizer, device, start_context)\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c1e23d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38c1e23d",
        "outputId": "5d6829a6-e367-4a09-da15-29e91e18f073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, step 2: train_loss = 8.618, val_loss = 8.164, tokens_seen = 1024\n",
            "Epoch 1, step 4: train_loss = 7.466, val_loss = 7.590, tokens_seen = 2048\n",
            "Epoch 1, step 6: train_loss = 8.427, val_loss = 8.799, tokens_seen = 3072\n",
            "Epoch 1, step 8: train_loss = 8.495, val_loss = 8.532, tokens_seen = 4096\n",
            "Every effort moves you fact not eyes would in..I it her- that And ofis.. in him he. a in not who notthe would St that it been. G G--.roud? he her\".I in out- he It painting\n",
            "Epoch 2, step 10: train_loss = 7.379, val_loss = 8.328, tokens_seen = 5120\n",
            "Epoch 2, step 12: train_loss = 7.697, val_loss = 8.376, tokens_seen = 6144\n",
            "Epoch 2, step 14: train_loss = 6.972, val_loss = 8.505, tokens_seen = 7168\n",
            "Epoch 2, step 16: train_loss = 6.948, val_loss = 8.401, tokens_seen = 8192\n",
            "Epoch 2, step 18: train_loss = 6.676, val_loss = 8.397, tokens_seen = 9216\n",
            "Every effort moves you my my\":. was he. it.. it.--burn to the as had. a. to I of with was't all-- my, it was to work I I had it it. about\" I my no a a you\n",
            "Epoch 3, step 20: train_loss = 6.829, val_loss = 8.511, tokens_seen = 10240\n",
            "Epoch 3, step 22: train_loss = 6.807, val_loss = 8.586, tokens_seen = 11264\n",
            "Epoch 3, step 24: train_loss = 6.388, val_loss = 8.484, tokens_seen = 12288\n",
            "Epoch 3, step 26: train_loss = 6.383, val_loss = 8.366, tokens_seen = 13312\n",
            "Every effort moves you, their the--,\"   roud had a, with , to Mrs the of, St the my he it . the, a and. under a and of   just?.,  the by a of,, he\n",
            "Epoch 4, step 28: train_loss = 6.555, val_loss = 8.388, tokens_seen = 14336\n",
            "Epoch 4, step 30: train_loss = 6.054, val_loss = 8.412, tokens_seen = 15360\n",
            "Epoch 4, step 32: train_loss = 6.377, val_loss = 8.237, tokens_seen = 16384\n",
            "Epoch 4, step 34: train_loss = 6.301, val_loss = 8.113, tokens_seen = 17408\n",
            "Epoch 4, step 36: train_loss = 6.055, val_loss = 8.040, tokens_seen = 18432\n",
            "Every effort moves you theI that and and.-- heI you I his me, how, he me to--'t't.., you to-- him was was me and to\"\" her one and't to.\" the and,I was he: was\n",
            "Epoch 5, step 38: train_loss = 6.361, val_loss = 8.009, tokens_seen = 19456\n",
            "Epoch 5, step 40: train_loss = 6.266, val_loss = 8.050, tokens_seen = 20480\n",
            "Epoch 5, step 42: train_loss = 6.422, val_loss = 8.028, tokens_seen = 21504\n",
            "Epoch 5, step 44: train_loss = 6.095, val_loss = 7.962, tokens_seen = 22528\n",
            "Every effort moves you-- with with the. have. of so it,\" his,,., and, he a and the, he,\"., hadis the G a a, in a of the.  , my in what, own, my of\n",
            "Epoch 6, step 46: train_loss = 6.099, val_loss = 7.948, tokens_seen = 23552\n",
            "Epoch 6, step 48: train_loss = 6.033, val_loss = 8.071, tokens_seen = 24576\n",
            "Epoch 6, step 50: train_loss = 6.013, val_loss = 8.125, tokens_seen = 25600\n",
            "Epoch 6, step 52: train_loss = 5.954, val_loss = 8.061, tokens_seen = 26624\n",
            "Epoch 6, step 54: train_loss = 6.017, val_loss = 7.919, tokens_seen = 27648\n",
            "Every effort moves you when he up her was he he the. in.  .. (. the the his\" the, him in his by me,, to the  I his was.\" with I the when.\"-- the   I his on not\n",
            "Epoch 7, step 56: train_loss = 6.106, val_loss = 7.887, tokens_seen = 28672\n",
            "Epoch 7, step 58: train_loss = 5.915, val_loss = 7.859, tokens_seen = 29696\n",
            "Epoch 7, step 60: train_loss = 5.849, val_loss = 7.760, tokens_seen = 30720\n",
            "Epoch 7, step 62: train_loss = 5.828, val_loss = 7.665, tokens_seen = 31744\n",
            "Every effort moves you on to  after the. St theis. _ , one to his. to,'s. the\". not him, him to one.  foundations--. I it to-- to and my to to, you.. But till\n",
            "Epoch 8, step 64: train_loss = 5.939, val_loss = 7.625, tokens_seen = 32768\n",
            "Epoch 8, step 66: train_loss = 5.723, val_loss = 7.678, tokens_seen = 33792\n",
            "Epoch 8, step 68: train_loss = 5.719, val_loss = 7.711, tokens_seen = 34816\n",
            "Epoch 8, step 70: train_loss = 5.864, val_loss = 7.776, tokens_seen = 35840\n",
            "Epoch 8, step 72: train_loss = 5.706, val_loss = 7.754, tokens_seen = 36864\n",
            "Every effort moves you her his not \"\" point,.I had one had---- a   wife he had a I of of,\" the And---.\"  is. G-- hisI the  first; a \" art up as me\n",
            "Epoch 9, step 74: train_loss = 5.886, val_loss = 7.733, tokens_seen = 37888\n",
            "Epoch 9, step 76: train_loss = 5.838, val_loss = 7.721, tokens_seen = 38912\n",
            "Epoch 9, step 78: train_loss = 5.711, val_loss = 7.671, tokens_seen = 39936\n",
            "Epoch 9, step 80: train_loss = 5.709, val_loss = 7.595, tokens_seen = 40960\n",
            "Every effort moves you. \"  ,--'s Mrs,---- to one him was Mrs,-- had in----,-- had in_, had a. . be own it it. was she my-- I, was a . show,.\"\n",
            "Epoch 10, step 82: train_loss = 5.820, val_loss = 7.592, tokens_seen = 41984\n",
            "Epoch 10, step 84: train_loss = 5.525, val_loss = 7.594, tokens_seen = 43008\n",
            "Epoch 10, step 86: train_loss = 5.784, val_loss = 7.578, tokens_seen = 44032\n",
            "Epoch 10, step 88: train_loss = 5.860, val_loss = 7.576, tokens_seen = 45056\n",
            "Epoch 10, step 90: train_loss = 5.593, val_loss = 7.516, tokens_seen = 46080\n",
            "Every effort moves you been  \" up of.  is a I of in the    is a Th\"  Well.The .   wall one.\"--  I a  tricks, to theI-- . \n"
          ]
        }
      ],
      "source": [
        "#train the model\n",
        "torch.manual_seed(123)\n",
        "model = GPTmodel(GPT_CONFIG_124M).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.004, weight_decay=0.01)\n",
        "num_epochs = 10\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model(model=model, train_loader=train_dataloader, val_loader=val_dataloader, optimizer=optimizer,\n",
        "                                                    device=device, num_epochs=num_epochs, eval_freq=4, eval_iter=4,\n",
        "                                                    start_context=\"Every effort moves you\", tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df940976",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df940976",
        "outputId": "0a2a94fa-427f-49b6-85ce-11c7024ae05e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every effort moves you the his the,, me, theYes the  wife, of have. \" it of.   \" I to the    little, on,'s you.   Oh the,. Yes he- the\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "generate_and_print(model, tokenizer, device, start_context='Every effort moves you')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oPAkIgvZXSS8",
      "metadata": {
        "id": "oPAkIgvZXSS8"
      },
      "source": [
        "Saving and loading model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87ea7fc",
      "metadata": {
        "id": "e87ea7fc"
      },
      "outputs": [],
      "source": [
        "#saves the model weight to given path\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "torch.save(model.state_dict(), 'gpt2_rand_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b920df2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b920df2",
        "outputId": "59f28431-1dda-4def-91d1-b93b86b86de8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load the model weights into new gptmodel model instance\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load('gpt2_rand_weights.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a65a4b1f",
      "metadata": {
        "id": "a65a4b1f"
      },
      "outputs": [],
      "source": [
        "#to save both model weights and optimizer parameters\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2023c784",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2023c784",
        "outputId": "e76028ae-cdee-47ac-d19d-9e5ddb16e24d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTmodel(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loads both model weights and optimizer parameter for each weight\n",
        "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
        "model = GPTmodel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c284f8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c284f8d",
        "outputId": "eaa0695a-f9fe-4b1e-f50f-5af4d0610b22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "162419712"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u9HfFvniWisZ",
      "metadata": {
        "id": "u9HfFvniWisZ"
      },
      "source": [
        "# Loading Pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "590e4666",
      "metadata": {
        "id": "590e4666"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46536875",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "8e8e57657d01444fb53099dd1ad9e91f",
            "06c60e5ddd2a44749be0cf496728bd41",
            "c52014e636644a8bbf36af7a0e675cfd",
            "6602fc5721c445a3b93a9beaae2be4a1",
            "51306772f89d42ccbf94a28c659a98b4",
            "6cc8d444b7414eb1b091f93bb39a66dd",
            "a27d25b2c08845f18cc3eab0aa1c0675",
            "1e3509c630af4e1d93537834766f78d2",
            "9725d1c35c8c479a9ce5c049f88ffe80",
            "1ddfab07551c44df87e1f8faddacdeee",
            "e6639aa8a55b4b77994361650a381a9b",
            "3a6f8f46126e4cb78aaedcd70e74a200",
            "a1654069382b4c04ad5ab480eaaaba51",
            "4cd195d22eed491f98bdc63b6d851a4f",
            "fc0585a1666d4b0a8f5c6c0fca74d18b",
            "4dc468f4667d460c82dd17f15c0f0857",
            "5761439544f44d3984fbbc6e9573c9e9",
            "d6db2b44f7674bb09ad100c4464a8776",
            "1e7d69871aeb44a284e28ff08de32986",
            "f8998c0820454e6b8029a22d97b4dced",
            "5e590edaaf634a869031e4c0d4f25599",
            "bef84d2ca11042ceaa7b08bcefb5e838",
            "9e17e99481464471b0d5622b2860b2d4",
            "a6aca18f95f6437fb83e9913be450adf",
            "8d536187aa8d4bc0b54a78bc489c2c90",
            "bcb05f1d439c4b07ae5984a8f85bb6cf",
            "90e3c047db144ae7bca91e7b971ee2c0",
            "c2d24b5281004f7ca9775ac59892a264",
            "f56504e73df94cc8a2adefda81cc6f24",
            "c3ea7d7d619f4754946c58d9955d6fd6",
            "cd384d195df64b9cb6d34e29fd85d66b",
            "4bf34e95ca334295a3ee5063f49dc56b",
            "06d276641e77412cbc372d27142e1f55"
          ]
        },
        "id": "46536875",
        "outputId": "721926cd-396b-43ef-acf8-6c56d6a31cf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e8e57657d01444fb53099dd1ad9e91f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a6f8f46126e4cb78aaedcd70e74a200",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e17e99481464471b0d5622b2860b2d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#load pretrained gpt2 model and tokenizer from huggingface transformers library\n",
        "model_name = 'gpt2'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model_new = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3def69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce3def69",
        "outputId": "84548c9e-118e-4241-9973-64acac28d84a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformer.wte.weight  torch.Size([50257, 768])\n",
            "transformer.wpe.weight  torch.Size([1024, 768])\n",
            "transformer.h.0.ln_1.weight  torch.Size([768])\n",
            "transformer.h.0.ln_1.bias  torch.Size([768])\n",
            "transformer.h.0.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.0.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.0.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.0.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.0.ln_2.weight  torch.Size([768])\n",
            "transformer.h.0.ln_2.bias  torch.Size([768])\n",
            "transformer.h.0.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.0.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.0.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.0.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.1.ln_1.weight  torch.Size([768])\n",
            "transformer.h.1.ln_1.bias  torch.Size([768])\n",
            "transformer.h.1.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.1.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.1.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.1.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.1.ln_2.weight  torch.Size([768])\n",
            "transformer.h.1.ln_2.bias  torch.Size([768])\n",
            "transformer.h.1.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.1.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.1.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.1.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.2.ln_1.weight  torch.Size([768])\n",
            "transformer.h.2.ln_1.bias  torch.Size([768])\n",
            "transformer.h.2.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.2.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.2.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.2.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.2.ln_2.weight  torch.Size([768])\n",
            "transformer.h.2.ln_2.bias  torch.Size([768])\n",
            "transformer.h.2.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.2.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.2.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.2.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.3.ln_1.weight  torch.Size([768])\n",
            "transformer.h.3.ln_1.bias  torch.Size([768])\n",
            "transformer.h.3.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.3.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.3.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.3.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.3.ln_2.weight  torch.Size([768])\n",
            "transformer.h.3.ln_2.bias  torch.Size([768])\n",
            "transformer.h.3.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.3.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.3.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.3.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.4.ln_1.weight  torch.Size([768])\n",
            "transformer.h.4.ln_1.bias  torch.Size([768])\n",
            "transformer.h.4.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.4.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.4.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.4.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.4.ln_2.weight  torch.Size([768])\n",
            "transformer.h.4.ln_2.bias  torch.Size([768])\n",
            "transformer.h.4.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.4.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.4.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.4.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.5.ln_1.weight  torch.Size([768])\n",
            "transformer.h.5.ln_1.bias  torch.Size([768])\n",
            "transformer.h.5.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.5.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.5.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.5.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.5.ln_2.weight  torch.Size([768])\n",
            "transformer.h.5.ln_2.bias  torch.Size([768])\n",
            "transformer.h.5.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.5.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.5.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.5.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.6.ln_1.weight  torch.Size([768])\n",
            "transformer.h.6.ln_1.bias  torch.Size([768])\n",
            "transformer.h.6.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.6.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.6.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.6.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.6.ln_2.weight  torch.Size([768])\n",
            "transformer.h.6.ln_2.bias  torch.Size([768])\n",
            "transformer.h.6.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.6.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.6.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.6.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.7.ln_1.weight  torch.Size([768])\n",
            "transformer.h.7.ln_1.bias  torch.Size([768])\n",
            "transformer.h.7.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.7.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.7.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.7.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.7.ln_2.weight  torch.Size([768])\n",
            "transformer.h.7.ln_2.bias  torch.Size([768])\n",
            "transformer.h.7.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.7.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.7.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.7.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.8.ln_1.weight  torch.Size([768])\n",
            "transformer.h.8.ln_1.bias  torch.Size([768])\n",
            "transformer.h.8.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.8.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.8.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.8.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.8.ln_2.weight  torch.Size([768])\n",
            "transformer.h.8.ln_2.bias  torch.Size([768])\n",
            "transformer.h.8.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.8.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.8.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.8.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.9.ln_1.weight  torch.Size([768])\n",
            "transformer.h.9.ln_1.bias  torch.Size([768])\n",
            "transformer.h.9.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.9.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.9.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.9.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.9.ln_2.weight  torch.Size([768])\n",
            "transformer.h.9.ln_2.bias  torch.Size([768])\n",
            "transformer.h.9.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.9.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.9.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.9.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.10.ln_1.weight  torch.Size([768])\n",
            "transformer.h.10.ln_1.bias  torch.Size([768])\n",
            "transformer.h.10.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.10.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.10.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.10.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.10.ln_2.weight  torch.Size([768])\n",
            "transformer.h.10.ln_2.bias  torch.Size([768])\n",
            "transformer.h.10.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.10.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.10.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.10.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.h.11.ln_1.weight  torch.Size([768])\n",
            "transformer.h.11.ln_1.bias  torch.Size([768])\n",
            "transformer.h.11.attn.c_attn.weight  torch.Size([768, 2304])\n",
            "transformer.h.11.attn.c_attn.bias  torch.Size([2304])\n",
            "transformer.h.11.attn.c_proj.weight  torch.Size([768, 768])\n",
            "transformer.h.11.attn.c_proj.bias  torch.Size([768])\n",
            "transformer.h.11.ln_2.weight  torch.Size([768])\n",
            "transformer.h.11.ln_2.bias  torch.Size([768])\n",
            "transformer.h.11.mlp.c_fc.weight  torch.Size([768, 3072])\n",
            "transformer.h.11.mlp.c_fc.bias  torch.Size([3072])\n",
            "transformer.h.11.mlp.c_proj.weight  torch.Size([3072, 768])\n",
            "transformer.h.11.mlp.c_proj.bias  torch.Size([768])\n",
            "transformer.ln_f.weight  torch.Size([768])\n",
            "transformer.ln_f.bias  torch.Size([768])\n",
            "lm_head.weight  torch.Size([50257, 768])\n"
          ]
        }
      ],
      "source": [
        "param = model_new.state_dict()\n",
        "for key in param:\n",
        "  print(key, \"\", param[key].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5cd451",
      "metadata": {
        "id": "4c5cd451"
      },
      "outputs": [],
      "source": [
        "#configuration for GPT model having 124 million parameters\n",
        "NEW_CONFIG = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.2,\n",
        "    \"qkv_bias\": True\n",
        "}\n",
        "gpt = GPTmodel(NEW_CONFIG)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OGYHFyv_oaUk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGYHFyv_oaUk",
        "outputId": "097f6633-8508-4dc0-c296-e667213a68ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([768, 2304])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_new.transformer.h[0].mlp.c_proj.bias[:5]\n",
        "len(model_new.transformer.h)\n",
        "model_new.transformer.h[0].attn.c_attn.weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-OC5FNVjfQCM",
      "metadata": {
        "id": "-OC5FNVjfQCM"
      },
      "outputs": [],
      "source": [
        "def load_weights_into_gpt(gpt, model_new):\n",
        "  with torch.no_grad():\n",
        "    gpt.token_emb.weight.copy_(model_new.transformer.wte.weight)\n",
        "    gpt.pos_emb.weight.copy_(model_new.transformer.wpe.weight)\n",
        "\n",
        "    for i in range(len(model_new.transformer.h)):\n",
        "\n",
        "      qkv_w = model_new.transformer.h[i].attn.c_attn.weight\n",
        "      q_w, k_w, v_w = torch.split(qkv_w,gpt.trf_blocks[i].attn.W_q.weight.shape[0],dim=-1)\n",
        "      gpt.trf_blocks[i].attn.W_q.weight.copy_(q_w.T)\n",
        "      gpt.trf_blocks[i].attn.W_k.weight.copy_(k_w.T)\n",
        "      gpt.trf_blocks[i].attn.W_v.weight.copy_(v_w.T)\n",
        "\n",
        "      qkv_b = model_new.transformer.h[i].attn.c_attn.bias\n",
        "      q_b, k_b, v_b = torch.split(qkv_b,gpt.trf_blocks[i].attn.W_q.bias.shape[0],dim=-1)\n",
        "      gpt.trf_blocks[i].attn.W_q.bias.copy_(q_b)\n",
        "      gpt.trf_blocks[i].attn.W_k.bias.copy_(k_b)\n",
        "      gpt.trf_blocks[i].attn.W_v.bias.copy_(v_b)\n",
        "\n",
        "      gpt.trf_blocks[i].attn.out_proj.weight.copy_(model_new.transformer.h[i].attn.c_proj.weight.T)\n",
        "      gpt.trf_blocks[i].attn.out_proj.bias.copy_(model_new.transformer.h[i].attn.c_proj.bias)\n",
        "\n",
        "      gpt.trf_blocks[i].ff.layers[0].weight.copy_(model_new.transformer.h[i].mlp.c_fc.weight.T)\n",
        "      gpt.trf_blocks[i].ff.layers[0].bias.copy_(model_new.transformer.h[i].mlp.c_fc.bias)\n",
        "      gpt.trf_blocks[i].ff.layers[2].weight.copy_(model_new.transformer.h[i].mlp.c_proj.weight.T)\n",
        "      gpt.trf_blocks[i].ff.layers[2].bias.copy_(model_new.transformer.h[i].mlp.c_proj.bias)\n",
        "\n",
        "      gpt.trf_blocks[i].norm1.scale.copy_(model_new.transformer.h[i].ln_1.weight)\n",
        "      gpt.trf_blocks[i].norm1.shift.copy_(model_new.transformer.h[i].ln_1.bias)\n",
        "      gpt.trf_blocks[i].norm2.scale.copy_(model_new.transformer.h[i].ln_2.weight)\n",
        "      gpt.trf_blocks[i].norm2.shift.copy_(model_new.transformer.h[i].ln_2.bias)\n",
        "\n",
        "    gpt.final_norm.scale.copy_(model_new.transformer.ln_f.weight)\n",
        "    gpt.final_norm.shift.copy_(model_new.transformer.ln_f.bias)\n",
        "    gpt.out_head.weight.copy_(model_new.transformer.wte.weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kFvsMf8Qvpmm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFvsMf8Qvpmm",
        "outputId": "94542317-afe8-4568-9fe8-15399446d6a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTmodel(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_weights_into_gpt(gpt,model_new)\n",
        "gpt.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pLmL5q3mH58d",
      "metadata": {
        "id": "pLmL5q3mH58d"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WsnBSlMsvpj2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsnBSlMsvpj2",
        "outputId": "80465502-27ed-4666-b501-b9e55964ffbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every effort moves you as far as the eye can see. (That's because you're not going to be able to see it all.) I think the most interesting thing about this is that there's an easy way to avoid it. You can get that with a couple\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "generated_tokens = generate_text(gpt, text_to_token_ids(\"Every effort moves you\", tokenizer).to(device), max_new_tokens=50,\n",
        "                                context_size=NEW_CONFIG[\"context_length\"], temperature=0.8, top_k=50, eos_id=tokenizer.eot_token)\n",
        "\n",
        "output = token_ids_to_text(generated_tokens, tokenizer)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uK2NOJvwWU4B",
      "metadata": {
        "id": "uK2NOJvwWU4B"
      },
      "source": [
        "# Classification Finetuning using pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DMtYmOIqfP1v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "collapsed": true,
        "id": "DMtYmOIqfP1v",
        "outputId": "c2b93c77-771e-42a8-8002-b5d302893cf9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df1"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-616daa04-0274-4b47-9584-a9eb47bfc97f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-616daa04-0274-4b47-9584-a9eb47bfc97f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-616daa04-0274-4b47-9584-a9eb47bfc97f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-616daa04-0274-4b47-9584-a9eb47bfc97f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_b75f0685-4755-4aa5-88c8-5fbc28cdf34d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b75f0685-4755-4aa5-88c8-5fbc28cdf34d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#finetuning for classification dataset (sms spam or not)\n",
        "# df1 = pd.read_csv(\"/content/drive/MyDrive/Dataset/email+sms+spam+collection/SMSSpamCollection\",sep=\"\\t\", names=[\"Label\",\"Text\"])\n",
        "df1 = pd.read_csv(\"/content/drive/MyDrive/Khanakh/Dataset/email+sms+spam+collection/SMSSpamCollection\",sep=\"\\t\", names=[\"Label\",\"Text\"])\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rybesm8uLOaM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Rybesm8uLOaM",
        "outputId": "87fbec70-1c25-47ef-9129-9df745146e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ham' 'spam']\n",
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df1[\"Label\"].unique())\n",
        "print(df1[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KiJf6BiTLOXb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "collapsed": true,
        "id": "KiJf6BiTLOXb",
        "outputId": "392fb7bb-8fe9-4120-a817-663994751ba2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 10961,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ham\",\n          \"spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10286,\n        \"samples\": [\n          \"SERIOUSLY. TELL HER THOSE EXACT WORDS RIGHT NOW.\",\n          \"Dhoni have luck to win some big title.so we will win:)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df2"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-838ae616-a311-49cc-829a-d68b920f0366\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spam</td>\n",
              "      <td>Congratulations! You've been selected for a lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>URGENT: Your account has been compromised. Cli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>You've won a free iPhone! Claim your prize by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spam</td>\n",
              "      <td>Act now and receive a 50% discount on all purc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>Important notice: Your subscription will expir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10956</th>\n",
              "      <td>spam</td>\n",
              "      <td>Hey little one! Exciting news! Mama and baby a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10957</th>\n",
              "      <td>spam</td>\n",
              "      <td>Amazing DATA deals on your Pulse Plan today! D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10958</th>\n",
              "      <td>spam</td>\n",
              "      <td>Special offer just for you! Get 1GB @15 bob va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10959</th>\n",
              "      <td>spam</td>\n",
              "      <td>NEW ARRIVAL - JUNE 23RD  Dresses @ 300; Kondel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10960</th>\n",
              "      <td>spam</td>\n",
              "      <td>Coureen, did you know that saving on Timiza in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10961 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-838ae616-a311-49cc-829a-d68b920f0366')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-838ae616-a311-49cc-829a-d68b920f0366 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-838ae616-a311-49cc-829a-d68b920f0366');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_8be1119c-34d2-44f1-8e46-5180a82a47a5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8be1119c-34d2-44f1-8e46-5180a82a47a5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      target                                               text\n",
              "0       spam  Congratulations! You've been selected for a lu...\n",
              "1       spam  URGENT: Your account has been compromised. Cli...\n",
              "2       spam  You've won a free iPhone! Claim your prize by ...\n",
              "3       spam  Act now and receive a 50% discount on all purc...\n",
              "4       spam  Important notice: Your subscription will expir...\n",
              "...      ...                                                ...\n",
              "10956   spam  Hey little one! Exciting news! Mama and baby a...\n",
              "10957   spam  Amazing DATA deals on your Pulse Plan today! D...\n",
              "10958   spam  Special offer just for you! Get 1GB @15 bob va...\n",
              "10959   spam  NEW ARRIVAL - JUNE 23RD  Dresses @ 300; Kondel...\n",
              "10960   spam  Coureen, did you know that saving on Timiza in...\n",
              "\n",
              "[10961 rows x 2 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df2 = pd.read_csv(\"/content/drive/MyDrive/Dataset/email+sms+spam+collection/SMS_Spam_dataset.csv\")\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Khanakh/Dataset/email+sms+spam+collection/SMS_Spam_dataset.csv\")\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5_5KuNAALONB",
      "metadata": {
        "collapsed": true,
        "id": "5_5KuNAALONB"
      },
      "outputs": [],
      "source": [
        "df2.rename(columns={'target':'Label', 'text':'Text'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q8qpWBqhLOKc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "collapsed": true,
        "id": "q8qpWBqhLOKc",
        "outputId": "f28831cc-caae-4912-cccf-e614c792cd4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>8555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>2406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Label\n",
              "ham     8555\n",
              "spam    2406\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ARxvSgwYLOHk",
      "metadata": {
        "collapsed": true,
        "id": "ARxvSgwYLOHk"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df1,df2], ignore_index=True, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SjG5RXnzLOE1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "collapsed": true,
        "id": "SjG5RXnzLOE1",
        "outputId": "3c1d5c52-9e25-455a-ab7a-638508bb2ca9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df[df\",\n  \"rows\": 5690,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4958,\n        \"samples\": [\n          \"Just do what ever is easier for you\",\n          \"I meant middle left or right?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5316f521-1994-47fe-b3d2-c39a55085b9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>ham</td>\n",
              "      <td>As I entered my cabin my PA said, '' Happy B'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>ham</td>\n",
              "      <td>No calls..messages..missed calls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16418</th>\n",
              "      <td>spam</td>\n",
              "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16421</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16422</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16423</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16430</th>\n",
              "      <td>ham</td>\n",
              "      <td>AFE Model Casting Call  Model Casting Call\\nTh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5690 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5316f521-1994-47fe-b3d2-c39a55085b9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5316f521-1994-47fe-b3d2-c39a55085b9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5316f521-1994-47fe-b3d2-c39a55085b9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Label                                               Text\n",
              "103     ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "154     ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "207     ham  As I entered my cabin my PA said, '' Happy B'd...\n",
              "223     ham                             Sorry, I'll call later\n",
              "326     ham                   No calls..messages..missed calls\n",
              "...     ...                                                ...\n",
              "16418  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
              "16421   ham  Pity, * was in mood for that. So...any other s...\n",
              "16422   ham  The guy did some bitching but I acted like i'd...\n",
              "16423   ham                         Rofl. Its true to its name\n",
              "16430   ham  AFE Model Casting Call  Model Casting Call\\nTh...\n",
              "\n",
              "[5690 rows x 2 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lXiZwEvWq94S",
      "metadata": {
        "collapsed": true,
        "id": "lXiZwEvWq94S"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(ignore_index=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a-1GjTocq9yT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "a-1GjTocq9yT",
        "outputId": "589ca02e-6728-473e-c6cc-1ab5618271e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df[df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ham\",\n          \"spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Your Account Was Accessed From a New Device We noticed a new login\\nHello ondiekijohn254@gmail.com, we noticed an unusual login from a device or location you don't usually use.\\nWas this you?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ffe62be4-28e5-4384-8ce3-7700353aebf6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10810</th>\n",
              "      <td>spam</td>\n",
              "      <td>Your Account Was Accessed From a New Device We...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10811</th>\n",
              "      <td>ham</td>\n",
              "      <td>Your Account Was Accessed From a New Device We...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffe62be4-28e5-4384-8ce3-7700353aebf6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ffe62be4-28e5-4384-8ce3-7700353aebf6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ffe62be4-28e5-4384-8ce3-7700353aebf6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Label                                               Text\n",
              "10810  spam  Your Account Was Accessed From a New Device We...\n",
              "10811   ham  Your Account Was Accessed From a New Device We..."
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df.duplicated(subset='Text', keep=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kOu2-OcYq9vh",
      "metadata": {
        "collapsed": true,
        "id": "kOu2-OcYq9vh"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(subset='Text', ignore_index=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "omR5lnCMq9sl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "collapsed": true,
        "id": "omR5lnCMq9sl",
        "outputId": "54a0339b-ec52-4ef4-fdc8-a3c60f5c707b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>8341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>2501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Label\n",
              "ham     8341\n",
              "spam    2501\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RjeFMGv2q9pb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "collapsed": true,
        "id": "RjeFMGv2q9pb",
        "outputId": "efdecb0c-750c-4d70-d7cb-062994aa2985"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>2501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>2501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Label\n",
              "ham     2501\n",
              "spam    2501\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#keep equal number of data for both labels\n",
        "def create_balanced_dataset(df):\n",
        "  num_spam = df[df['Label']=='spam'].shape[0]\n",
        "  ham_subset = df[df['Label']=='ham'].sample(num_spam, random_state=123)\n",
        "  balanced_df = pd.concat([ham_subset, df[df['Label']=='spam']])\n",
        "\n",
        "  return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "balanced_df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P6pJiiUGq9jU",
      "metadata": {
        "id": "P6pJiiUGq9jU"
      },
      "outputs": [],
      "source": [
        "#convert the label column value spam and ham into 1 and o\n",
        "balanced_df['Label'] = pd.factorize(balanced_df['Label'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wIqt4k4zvarI",
      "metadata": {
        "collapsed": true,
        "id": "wIqt4k4zvarI"
      },
      "outputs": [],
      "source": [
        "#split the dataset into train, validation and test\n",
        "def random_split(df, train_frac, val_frac):\n",
        "  #shuffle the dataset before sampling and reset the index\n",
        "  df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "  #calculate split ends\n",
        "  train_end = int(len(df)*train_frac)\n",
        "  val_end = train_end + int(len(df)*val_frac)\n",
        "\n",
        "  #split the dataset\n",
        "  train_df = df[:train_end]\n",
        "  validation_df = df[train_end:val_end]\n",
        "  test_df = df[val_end:]\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fuxYg-_wOj4F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuxYg-_wOj4F",
        "outputId": "21eaa6b3-6e57-47c1-93a3-0f919546e002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3501 500 1001\n"
          ]
        }
      ],
      "source": [
        "print(len(train_df), len(validation_df), len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4O0Tpe8Tvaoo",
      "metadata": {
        "id": "4O0Tpe8Tvaoo"
      },
      "outputs": [],
      "source": [
        "#save the dataset as csv format to use it later\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "maYvb3GrvamV",
      "metadata": {
        "id": "maYvb3GrvamV"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "#class to equalize the sequence length of all data input by padding eos tokenid\n",
        "class padding_dataset(Dataset):\n",
        "  def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "    #pretokenized text\n",
        "    self.encoded_texts = [tokenizer.encode(text) for text in self.data['Text']]\n",
        "\n",
        "    if max_length is None:\n",
        "      self.max_length = self._longest_encoded_length()\n",
        "    else:\n",
        "      self.max_length = max_length\n",
        "\n",
        "      #truncate sequences length to match with maximum length\n",
        "      self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
        "\n",
        "    #pad eos tokenid to sequences to match with maximum length\n",
        "    self.encoded_text = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts]\n",
        "\n",
        "  #returns encoded_text and label in tensor form\n",
        "  def __getitem__(self, index):\n",
        "    encoded = self.encoded_text[index]\n",
        "    label = self.data.iloc[index]['Label']\n",
        "\n",
        "    return(torch.tensor(encoded, dtype=torch.long),\n",
        "           torch.tensor(label, dtype=torch.long))\n",
        "\n",
        "  def __len__(self):\n",
        "    return(len(self.data))\n",
        "\n",
        "  #returns the sequence length containing max length\n",
        "  def _longest_encoded_length(self):\n",
        "    max_length=0\n",
        "    for encoded_text in self.encoded_texts:\n",
        "      encoded_length = len(encoded_text)\n",
        "      if encoded_length > max_length:\n",
        "        max_length = encoded_length\n",
        "    return max_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ubaMJ3EavajV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubaMJ3EavajV",
        "outputId": "523ed3e7-0da9-4209-ecc2-e71ece4bee0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1024\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3501"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = padding_dataset(csv_file='train.csv', max_length=NEW_CONFIG[\"context_length\"], tokenizer=tokenizer)\n",
        "print(train_dataset.max_length)\n",
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j4pIxvruvagi",
      "metadata": {
        "id": "j4pIxvruvagi"
      },
      "outputs": [],
      "source": [
        "test_dataset = padding_dataset(csv_file='test.csv', max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
        "val_dataset = padding_dataset(csv_file='validation.csv', max_length=train_dataset.max_length, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Et-xnPg4vaaL",
      "metadata": {
        "id": "Et-xnPg4vaaL"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 25\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "#create a batches of dataset with max_length as sequence length and batch_size/total sequence per batch as 8\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aBeLSeChPSyk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBeLSeChPSyk",
        "outputId": "a95bf16e-ecba-4bf1-fea4-02c7defeecf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([25, 1024]) torch.Size([25])\n"
          ]
        }
      ],
      "source": [
        "for input, target in train_loader:\n",
        "  print(input.shape, target.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BSDN4OhRq2PH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSDN4OhRq2PH",
        "outputId": "a915f254-02db-4e12-9677-2abdf2c95cea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader) #total training batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wvRDE-dzPSt3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvRDE-dzPSt3",
        "outputId": "e3919455-0ca0-454e-d9e0-25fd9f498508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPTmodel(\n",
            "  (token_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#we need to modify new pretrained model for classification finetuning\n",
        "#for that we have to modify output layer which map the hidden representation to vocabulary size\n",
        "#with a smaller ouput layer that maps two classes:0 (not spam),1(spam)\n",
        "print(gpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hdZKg3ccPSrj",
      "metadata": {
        "id": "hdZKg3ccPSrj"
      },
      "outputs": [],
      "source": [
        "#make alllayers of gpt model non trainable to modify\n",
        "for param in gpt.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#modify the output dimension of out_head\n",
        "torch.manual_seed(123)\n",
        "num_classes = 2\n",
        "gpt.out_head = torch.nn.Linear(NEW_CONFIG['emb_dim'], num_classes, bias=True).to(device)\n",
        "#by default require_grad is true for out_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IrV4-vv8PSo-",
      "metadata": {
        "id": "IrV4-vv8PSo-"
      },
      "outputs": [],
      "source": [
        "#set the require_grad attribute true for last transformer block and for final normalization layer to make them trainable\n",
        "for param in gpt.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in gpt.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iIPI9lrKPSmh",
      "metadata": {
        "id": "iIPI9lrKPSmh"
      },
      "outputs": [],
      "source": [
        "#function to calculate accuracy\n",
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "  model.eval()\n",
        "  correct_predictions, num_examples = 0, 0\n",
        "\n",
        "  if num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch, target_batch)in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = model(input_batch)[:,-1,:]\n",
        "      predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "      num_examples += predicted_labels.shape[0]\n",
        "      correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  return correct_predictions/num_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NYJzxMRFPSkC",
      "metadata": {
        "id": "NYJzxMRFPSkC"
      },
      "outputs": [],
      "source": [
        "#function to calculate loss of a batch but only of last token\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss\n",
        "\n",
        "#function to calculate loss of given batches\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bs4P2tngPShL",
      "metadata": {
        "id": "bs4P2tngPShL"
      },
      "outputs": [],
      "source": [
        "#function to train the model\n",
        "def train_classifier(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
        "  train_losses, val_losses, train_acc, val_acc = [], [], [], []\n",
        "  examples_seen, global_step = 0,0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      examples_seen += input_batch.shape[0]\n",
        "\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:4d}): Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "      global_step += 1\n",
        "\n",
        "    #calculate accuracy after each epoch\n",
        "    train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "    val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "    print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "    train_acc.append(train_accuracy)\n",
        "    val_acc.append(val_accuracy)\n",
        "    global_step = 0\n",
        "\n",
        "  return train_losses, val_losses, train_acc, val_acc, examples_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suiMfxv2aKhf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suiMfxv2aKhf",
        "outputId": "f58caf9f-bba1-4711-c5ff-9ed62454642f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step    0): Train loss 0.833, Val loss 0.787\n",
            "Ep 1 (Step   50): Train loss 0.658, Val loss 0.725\n",
            "Ep 1 (Step  100): Train loss 0.514, Val loss 0.637\n",
            "Training accuracy: 74.40% | Validation accuracy: 70.40%\n",
            "Ep 2 (Step    0): Train loss 0.510, Val loss 0.585\n",
            "Ep 2 (Step   50): Train loss 0.371, Val loss 0.454\n",
            "Ep 2 (Step  100): Train loss 0.299, Val loss 0.396\n",
            "Training accuracy: 87.20% | Validation accuracy: 83.20%\n",
            "Ep 3 (Step    0): Train loss 0.320, Val loss 0.382\n",
            "Ep 3 (Step   50): Train loss 0.302, Val loss 0.358\n",
            "Ep 3 (Step  100): Train loss 0.218, Val loss 0.278\n",
            "Training accuracy: 83.20% | Validation accuracy: 84.80%\n",
            "Ep 4 (Step    0): Train loss 0.297, Val loss 0.320\n",
            "Ep 4 (Step   50): Train loss 0.318, Val loss 0.315\n",
            "Ep 4 (Step  100): Train loss 0.234, Val loss 0.317\n",
            "Training accuracy: 94.40% | Validation accuracy: 91.20%\n",
            "Ep 5 (Step    0): Train loss 0.176, Val loss 0.234\n",
            "Ep 5 (Step   50): Train loss 0.175, Val loss 0.256\n",
            "Ep 5 (Step  100): Train loss 0.230, Val loss 0.407\n",
            "Training accuracy: 92.80% | Validation accuracy: 91.20%\n"
          ]
        }
      ],
      "source": [
        "gpt.to(device)\n",
        "gpt.train()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(gpt.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier(gpt, train_loader, val_loader, optimizer, device,\n",
        "                                                                                 num_epochs=num_epochs, eval_freq=50, eval_iter=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qs7nTc4DaKe4",
      "metadata": {
        "id": "Qs7nTc4DaKe4"
      },
      "outputs": [],
      "source": [
        "#function to classify sms\n",
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "  model.eval()\n",
        "  input_ids = tokenizer.encode(text)\n",
        "  context_length = model.pos_emb.weight.shape[0]\n",
        "  if max_length is None:\n",
        "    new_length = context_length\n",
        "  else:\n",
        "    new_length = min(max_length,context_length)\n",
        "\n",
        "  input_ids = input_ids[:new_length]\n",
        "\n",
        "  input_ids += [pad_token_id] * (context_length - len(input_ids))\n",
        "  input_tensors = torch.tensor(input_ids, device=device).unsqueeze(0) #add batch dimension\n",
        "\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensors)[:,-1,:]\n",
        "  predicted_labels = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "  return \"spam\" if predicted_labels==1 else \"not spam\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0Z-juRhmuikH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z-juRhmuikH",
        "outputId": "64b023b9-40ff-428c-e69a-51adc8b9f7f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spam\n"
          ]
        }
      ],
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, gpt, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YvnoHE4Tuihp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvnoHE4Tuihp",
        "outputId": "2f8333d2-c832-4ebf-cf93-67d832c4b9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "not spam\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, gpt, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5RzVVXtfGz05",
      "metadata": {
        "id": "5RzVVXtfGz05"
      },
      "outputs": [],
      "source": [
        "torch.save(gpt.state_dict(), \"review_classifier.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J_StnECiGzx5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_StnECiGzx5",
        "outputId": "c5c8100d-f814-41fc-e1cc-d91ec8d20b10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\")\n",
        "gpt.load_state_dict(model_state_dict)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
